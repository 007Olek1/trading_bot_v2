#!/usr/bin/env python3
"""
üß† UNIVERSAL LEARNING SYSTEM V4.0
==================================

–°–∏—Å—Ç–µ–º–∞ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞–µ—Ç –ü–†–ê–í–ò–õ–ê, –∞ –Ω–µ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è
- –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–∞—Ö, –∞ –Ω–µ —Ç–æ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
- –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π
- –≠–≤–æ–ª—é—Ü–∏–æ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –º—É—Ç–∞—Ü–∏—è–º–∏ –∏ –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–æ–º
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–∏–ª
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
import logging
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import json
import random
from collections import defaultdict
import statistics
import pytz

logger = logging.getLogger(__name__)

# Warsaw timezone –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–∏
WARSAW_TZ = pytz.timezone('Europe/Warsaw')

@dataclass
class UniversalPattern:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω (–¥–∏–∞–ø–∞–∑–æ–Ω—ã, –Ω–µ —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)"""
    pattern_id: str
    feature_ranges: Dict[str, Tuple[float, float]]  # –î–∏–∞–ø–∞–∑–æ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    target_action: str  # 'buy', 'sell', 'hold'
    confidence_range: Tuple[float, float]
    market_conditions: List[str]
    success_rate: float
    sample_size: int
    generalization_score: float  # –ù–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –æ–±–æ–±—â–∞–µ—Ç
    created_at: str
    last_validation: str

@dataclass
class LearningRule:
    """–ü—Ä–∞–≤–∏–ª–æ –æ–±—É—á–µ–Ω–∏—è (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ)"""
    rule_id: str
    rule_name: str
    conditions: Dict[str, Any]  # –£—Å–ª–æ–≤–∏—è –≤ –≤–∏–¥–µ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    action: str
    priority: float
    success_history: List[bool]
    market_adaptability: Dict[str, float]  # –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–∞–∑–Ω—ã—Ö —É—Å–ª–æ–≤–∏—è—Ö
    evolution_generation: int
    parent_rules: List[str]  # –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞
    mutation_history: List[str]

class UniversalLearningSystem:
    """üß† –°–∏—Å—Ç–µ–º–∞ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self, data_storage=None):
        self.data_storage = data_storage
        self.patterns = {}
        self.rules = {}
        self.evolution_generation = 0
        self.learning_history = []
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
        self.min_sample_size = 10  # –ú–∏–Ω–∏–º—É–º –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª–∞
        self.min_success_rate = 0.50  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
        self.generalization_threshold = 0.50  # –ü–æ—Ä–æ–≥ –æ–±–æ–±—â–µ–Ω–∏—è (—Å–Ω–∏–∂–µ–Ω –¥–ª—è –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
        self.mutation_rate = 0.15  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º—É—Ç–∞—Ü–∏–∏
        self.crossover_rate = 0.25  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–∫—Ä–µ—â–∏–≤–∞–Ω–∏—è
        
        logger.info("üß† UniversalLearningSystem –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def analyze_market_patterns(self, market_data: List[Dict]) -> List[UniversalPattern]:
        """–ê–Ω–∞–ª–∏–∑ —Ä—ã–Ω–æ—á–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª"""
        try:
            if len(market_data) < self.min_sample_size:
                return []
            
            patterns = []
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
            successful_trades = [d for d in market_data if d.get('result') == 'win']
            failed_trades = [d for d in market_data if d.get('result') == 'loss']
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–¥–µ–ª–æ–∫
            if len(successful_trades) >= self.min_sample_size:
                success_pattern = self._create_pattern_from_data(
                    successful_trades, 'successful_entry', True
                )
                if success_pattern:
                    patterns.append(success_pattern)
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –Ω–µ—É–¥–∞—á–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ (—á—Ç–æ–±—ã –∏—Ö –∏–∑–±–µ–≥–∞—Ç—å)
            if len(failed_trades) >= self.min_sample_size:
                failure_pattern = self._create_pattern_from_data(
                    failed_trades, 'failed_entry', False
                )
                if failure_pattern:
                    patterns.append(failure_pattern)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ —Ä—ã–Ω–æ—á–Ω—ã–º —É—Å–ª–æ–≤–∏—è–º
            market_conditions = set([d.get('market_condition', 'NEUTRAL') for d in market_data])
            
            for condition in market_conditions:
                condition_data = [d for d in market_data if d.get('market_condition') == condition]
                if len(condition_data) >= self.min_sample_size:
                    condition_pattern = self._create_pattern_from_data(
                        condition_data, f'{condition.lower()}_market', None
                    )
                    if condition_pattern:
                        patterns.append(condition_pattern)
            
            logger.info(f"üß† –°–æ–∑–¥–∞–Ω–æ {len(patterns)} —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
            return patterns
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
            return []
    
    def _create_pattern_from_data(self, data: List[Dict], pattern_type: str, 
                                is_positive: Optional[bool]) -> Optional[UniversalPattern]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if len(data) < self.min_sample_size:
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            features = ['rsi', 'bb_position', 'volume_ratio', 'momentum', 'confidence', 'strategy_score']
            feature_ranges = {}
            
            for feature in features:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π —É—Ä–æ–≤–µ–Ω—å, –∑–∞—Ç–µ–º market_data
                values = []
                for d in data:
                    value = d.get(feature)
                    if value is None and 'market_data' in d:
                        value = d.get('market_data', {}).get(feature)
                    if value is not None:
                        try:
                            values.append(float(value))
                        except (ValueError, TypeError):
                            continue
                
                if len(values) >= 3:  # –ú–∏–Ω–∏–º—É–º 3 –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                    # –°–æ–∑–¥–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Å –∑–∞–ø–∞—Å–æ–º (–Ω–µ —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è!)
                    min_val = min(values)
                    max_val = max(values)
                    std_val = statistics.stdev(values) if len(values) > 1 else 0
                    
                    # –†–∞—Å—à–∏—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è –æ–±–æ–±—â–µ–Ω–∏—è
                    range_expansion = max(std_val, (max_val - min_val) * 0.1)
                    feature_ranges[feature] = (
                        max(0, min_val - range_expansion),
                        max_val + range_expansion
                    )
            
            if len(feature_ranges) < 3:  # –ú–∏–Ω–∏–º—É–º 3 –ø—Ä–∏–∑–Ω–∞–∫–∞
                return None
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
            actions = []
            for d in data:
                action = d.get('decision')
                if action:
                    actions.append(action)
            target_action = max(set(actions), key=actions.count) if actions else 'hold'
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            confidences = []
            for d in data:
                conf = d.get('confidence')
                if conf is None and 'market_data' in d:
                    conf = d.get('market_data', {}).get('confidence')
                if conf is not None:
                    try:
                        confidences.append(float(conf))
                    except (ValueError, TypeError):
                        continue
            confidence_range = (min(confidences), max(confidences)) if confidences else (40, 80)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            market_conditions = []
            for d in data:
                cond = d.get('market_condition') or d.get('market_data', {}).get('market_condition', 'NEUTRAL')
                market_conditions.append(cond)
            market_conditions = list(set(market_conditions))
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
            if is_positive is not None:
                success_rate = 0.8 if is_positive else 0.2  # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
            else:
                results = [d.get('result') for d in data if d.get('result')]
                wins = results.count('win')
                total = len([r for r in results if r in ['win', 'loss']])
                success_rate = wins / total if total > 0 else 0.5
            
            # –ï—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç—å —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è, –Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ - –ø–æ–≤—ã—à–∞–µ–º –µ—ë
            if is_positive is True and success_rate < self.min_success_rate:
                success_rate = max(self.min_success_rate, 0.6)  # –ú–∏–Ω–∏–º—É–º 60% –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º score –æ–±–æ–±—â–µ–Ω–∏—è
            generalization_score = self._calculate_generalization_score(feature_ranges, len(data))
            
            pattern = UniversalPattern(
                pattern_id=f"pattern_{pattern_type}_{datetime.now(WARSAW_TZ).strftime('%Y%m%d_%H%M%S')}",
                feature_ranges=feature_ranges,
                target_action=target_action,
                confidence_range=confidence_range,
                market_conditions=market_conditions,
                success_rate=success_rate,
                sample_size=len(data),
                generalization_score=generalization_score,
                created_at=datetime.now(WARSAW_TZ).isoformat(),
                last_validation=datetime.now(WARSAW_TZ).isoformat()
            )
            
            return pattern
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {e}")
            return None
    
    def _calculate_generalization_score(self, feature_ranges: Dict, sample_size: int) -> float:
        """–†–∞—Å—á–µ—Ç score –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏"""
        try:
            # –ß–µ–º —à–∏—Ä–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –∏ –±–æ–ª—å—à–µ –≤—ã–±–æ—Ä–∫–∞, —Ç–µ–º –ª—É—á—à–µ –æ–±–æ–±—â–µ–Ω–∏–µ
            range_widths = []
            for feature, (min_val, max_val) in feature_ranges.items():
                if max_val > min_val:
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —à–∏—Ä–∏–Ω—É –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                    if feature in ['rsi', 'bb_position']:
                        normalized_width = (max_val - min_val) / 100.0
                    elif feature in ['confidence', 'strategy_score']:
                        normalized_width = (max_val - min_val) / 20.0
                    else:
                        normalized_width = min(1.0, (max_val - min_val) / max_val)
                    
                    range_widths.append(normalized_width)
            
            avg_range_width = statistics.mean(range_widths) if range_widths else 0
            sample_factor = min(1.0, sample_size / 50.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã
            generalization_score = (avg_range_width * 0.6 + sample_factor * 0.4)
            
            return min(1.0, generalization_score)
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –æ–±–æ–±—â–µ–Ω–∏—è: {e}")
            return 0.5
    
    def create_universal_rules(self, patterns: List[UniversalPattern]) -> List[LearningRule]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤"""
        try:
            rules = []
            
            for pattern in patterns:
                # –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                logger.debug(f"üìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ {pattern.pattern_id}:")
                logger.debug(f"   Success rate: {pattern.success_rate:.2f} (—Ç—Ä–µ–±—É–µ—Ç—Å—è >= {self.min_success_rate:.2f})")
                logger.debug(f"   Generalization: {pattern.generalization_score:.2f} (—Ç—Ä–µ–±—É–µ—Ç—Å—è >= {self.generalization_threshold:.2f})")
                
                if (pattern.success_rate >= self.min_success_rate and 
                    pattern.generalization_score >= self.generalization_threshold):
                    
                    logger.debug(f"   ‚úÖ –ü–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø—Ä–æ–≤–µ—Ä–∫—É - —Å–æ–∑–¥–∞–µ–º –ø—Ä–∞–≤–∏–ª–æ")
                    rule = self._pattern_to_rule(pattern)
                    if rule:
                        rules.append(rule)
                        self.rules[rule.rule_id] = rule
                        logger.debug(f"   ‚úÖ –ü—Ä–∞–≤–∏–ª–æ {rule.rule_id} —Å–æ–∑–¥–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ")
                else:
                    failures = []
                    if pattern.success_rate < self.min_success_rate:
                        failures.append(f"success_rate ({pattern.success_rate:.2f} < {self.min_success_rate:.2f})")
                    if pattern.generalization_score < self.generalization_threshold:
                        failures.append(f"generalization ({pattern.generalization_score:.2f} < {self.generalization_threshold:.2f})")
                    logger.debug(f"   ‚ùå –ü–∞—Ç—Ç–µ—Ä–Ω –Ω–µ –ø—Ä–æ—à–µ–ª –ø—Ä–æ–≤–µ—Ä–∫—É: {', '.join(failures)}")
            
            logger.info(f"üß† –°–æ–∑–¥–∞–Ω–æ {len(rules)} —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –∏–∑ {len(patterns)} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")
            return rules
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª: {e}", exc_info=True)
            return []
    
    def get_learned_rules(self) -> List[LearningRule]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª"""
        return list(self.rules.values())
    
    def analyze_patterns(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            if not self.patterns:
                return {}
            
            analysis = {
                'total_patterns': len(self.patterns),
                'patterns_with_ranges': 0,
                'patterns_with_exact_values': 0,
                'average_generalization': 0.0,
                'patterns_by_action': defaultdict(int)
            }
            
            generalization_scores = []
            
            for pattern_id, pattern in self.patterns.items():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω—ã (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å)
                has_ranges = any(
                    isinstance(r, tuple) and len(r) == 2 
                    for r in pattern.feature_ranges.values()
                )
                
                if has_ranges:
                    analysis['patterns_with_ranges'] += 1
                else:
                    analysis['patterns_with_exact_values'] += 1
                
                generalization_scores.append(pattern.generalization_score)
                analysis['patterns_by_action'][pattern.target_action] += 1
            
            if generalization_scores:
                analysis['average_generalization'] = statistics.mean(generalization_scores)
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
            return {}
    
    def learn_from_decision(self, market_data: Dict, decision: str, result: str):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–Ω—è—Ç–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ—à–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
            learning_entry = {
                'market_data': market_data,
                'decision': decision,
                'result': result,
                'timestamp': datetime.now(WARSAW_TZ).isoformat(),
                'market_condition': market_data.get('market_condition', 'NEUTRAL')
            }
            
            self.learning_history.append(learning_entry)
            
            # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–∏–º–µ—Ä–æ–≤, —Å–æ–∑–¥–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            if len(self.learning_history) >= self.min_sample_size * 2:
                patterns = self.analyze_market_patterns(self.learning_history[-50:])  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50
                if patterns:
                    rules = self.create_universal_rules(patterns)
                    logger.debug(f"üß† –°–æ–∑–¥–∞–Ω–æ {len(rules)} –Ω–æ–≤—ã—Ö –ø—Ä–∞–≤–∏–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—É—á–µ–Ω–∏—è")
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
    
    def _pattern_to_rule(self, pattern: UniversalPattern) -> Optional[LearningRule]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –≤ –ø—Ä–∞–≤–∏–ª–æ"""
        try:
            # –°–æ–∑–¥–∞–µ–º —É—Å–ª–æ–≤–∏—è –ø—Ä–∞–≤–∏–ª–∞ (–¥–∏–∞–ø–∞–∑–æ–Ω—ã, –Ω–µ —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è!)
            conditions = {
                'feature_ranges': pattern.feature_ranges,
                'market_conditions': pattern.market_conditions,
                'confidence_range': pattern.confidence_range,
                'min_generalization': pattern.generalization_score
            }
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –∏ –æ–±–æ–±—â–µ–Ω–∏—è
            priority = (pattern.success_rate * 0.7 + pattern.generalization_score * 0.3)
            
            rule = LearningRule(
                rule_id=f"rule_{pattern.pattern_id}",
                rule_name=f"Universal {pattern.target_action} rule",
                conditions=conditions,
                action=pattern.target_action,
                priority=priority,
                success_history=[],
                market_adaptability={condition: pattern.success_rate for condition in pattern.market_conditions},
                evolution_generation=self.evolution_generation,
                parent_rules=[],
                mutation_history=[]
            )
            
            return rule
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –≤ –ø—Ä–∞–≤–∏–ª–æ: {e}")
            return None
    
    def evolve_rules(self, performance_data: List[Dict]) -> List[LearningRule]:
        """–≠–≤–æ–ª—é—Ü–∏—è –ø—Ä–∞–≤–∏–ª (–º—É—Ç–∞—Ü–∏–∏, –∫—Ä–æ—Å—Å–æ–≤–µ—Ä, —Å–µ–ª–µ–∫—Ü–∏—è)"""
        try:
            if len(self.rules) < 2:
                return list(self.rules.values())
            
            self.evolution_generation += 1
            evolved_rules = []
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–∞–≤–∏–ª
            rule_performance = self._evaluate_rule_performance(performance_data)
            
            # –°–µ–ª–µ–∫—Ü–∏—è –ª—É—á—à–∏—Ö –ø—Ä–∞–≤–∏–ª
            best_rules = self._select_best_rules(rule_performance, top_percent=0.6)
            
            # –ú—É—Ç–∞—Ü–∏–∏ –ª—É—á—à–∏—Ö –ø—Ä–∞–≤–∏–ª
            for rule in best_rules:
                if random.random() < self.mutation_rate:
                    mutated_rule = self._mutate_rule(rule)
                    if mutated_rule:
                        evolved_rules.append(mutated_rule)
            
            # –ö—Ä–æ—Å—Å–æ–≤–µ—Ä –º–µ–∂–¥—É –ª—É—á—à–∏–º–∏ –ø—Ä–∞–≤–∏–ª–∞–º–∏
            for i in range(len(best_rules)):
                for j in range(i + 1, len(best_rules)):
                    if random.random() < self.crossover_rate:
                        offspring = self._crossover_rules(best_rules[i], best_rules[j])
                        if offspring:
                            evolved_rules.extend(offspring)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ª—É—á—à–∏–µ –∏—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞
            evolved_rules.extend(best_rules)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é –ø—Ä–∞–≤–∏–ª
            self.rules = {rule.rule_id: rule for rule in evolved_rules}
            
            logger.info(f"üß¨ –≠–≤–æ–ª—é—Ü–∏—è –ø–æ–∫–æ–ª–µ–Ω–∏—è {self.evolution_generation}: {len(evolved_rules)} –ø—Ä–∞–≤–∏–ª")
            
            return evolved_rules
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç–≤–æ–ª—é—Ü–∏–∏ –ø—Ä–∞–≤–∏–ª: {e}")
            return list(self.rules.values())
    
    def _evaluate_rule_performance(self, performance_data: List[Dict]) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–∏–ª"""
        rule_performance = {}
        
        for rule_id, rule in self.rules.items():
            # –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ —É—Å–ø–µ—Ö–æ–≤
            if rule.success_history:
                base_score = sum(rule.success_history) / len(rule.success_history)
            else:
                base_score = rule.priority
            
            # –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å –∫ —Ä—ã–Ω–æ—á–Ω—ã–º —É—Å–ª–æ–≤–∏—è–º
            adaptability_score = statistics.mean(rule.market_adaptability.values())
            
            # –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
            performance_score = base_score * 0.7 + adaptability_score * 0.3
            rule_performance[rule_id] = performance_score
        
        return rule_performance
    
    def _select_best_rules(self, performance: Dict[str, float], top_percent: float = 0.6) -> List[LearningRule]:
        """–°–µ–ª–µ–∫—Ü–∏—è –ª—É—á—à–∏—Ö –ø—Ä–∞–≤–∏–ª"""
        sorted_rules = sorted(performance.items(), key=lambda x: x[1], reverse=True)
        top_count = max(1, int(len(sorted_rules) * top_percent))
        
        best_rule_ids = [rule_id for rule_id, _ in sorted_rules[:top_count]]
        return [self.rules[rule_id] for rule_id in best_rule_ids if rule_id in self.rules]
    
    def _mutate_rule(self, rule: LearningRule) -> Optional[LearningRule]:
        """–ú—É—Ç–∞—Ü–∏—è –ø—Ä–∞–≤–∏–ª–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –ø—Ä–∞–≤–∏–ª–∞
            mutated_conditions = rule.conditions.copy()
            
            # –ú—É—Ç–∏—Ä—É–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if 'feature_ranges' in mutated_conditions:
                feature_ranges = mutated_conditions['feature_ranges'].copy()
                
                # –°–ª—É—á–∞–π–Ω–æ –≤—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –º—É—Ç–∞—Ü–∏–∏
                if feature_ranges:
                    feature = random.choice(list(feature_ranges.keys()))
                    min_val, max_val = feature_ranges[feature]
                    
                    # –ú—É—Ç–∏—Ä—É–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω (—Ä–∞—Å—à–∏—Ä—è–µ–º –∏–ª–∏ —Å—É–∂–∞–µ–º)
                    range_width = max_val - min_val
                    mutation_factor = random.uniform(0.8, 1.2)  # ¬±20%
                    
                    new_width = range_width * mutation_factor
                    center = (min_val + max_val) / 2
                    
                    feature_ranges[feature] = (
                        max(0, center - new_width / 2),
                        center + new_width / 2
                    )
                
                mutated_conditions['feature_ranges'] = feature_ranges
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –ø—Ä–∞–≤–∏–ª–æ
            mutated_rule = LearningRule(
                rule_id=f"mutated_{rule.rule_id}_{self.evolution_generation}",
                rule_name=f"Mutated {rule.rule_name}",
                conditions=mutated_conditions,
                action=rule.action,
                priority=rule.priority * random.uniform(0.9, 1.1),  # –ù–µ–±–æ–ª—å—à–∞—è –º—É—Ç–∞—Ü–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
                success_history=[],
                market_adaptability=rule.market_adaptability.copy(),
                evolution_generation=self.evolution_generation,
                parent_rules=[rule.rule_id],
                mutation_history=rule.mutation_history + [f"gen_{self.evolution_generation}"]
            )
            
            return mutated_rule
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º—É—Ç–∞—Ü–∏–∏ –ø—Ä–∞–≤–∏–ª–∞: {e}")
            return None
    
    def _crossover_rules(self, rule1: LearningRule, rule2: LearningRule) -> List[LearningRule]:
        """–ö—Ä–æ—Å—Å–æ–≤–µ—Ä –º–µ–∂–¥—É –ø—Ä–∞–≤–∏–ª–∞–º–∏"""
        try:
            offspring = []
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ—Ç–æ–º–∫–∞, –∫–æ–º–±–∏–Ω–∏—Ä—É—è –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–æ–¥–∏—Ç–µ–ª–µ–π
            if ('feature_ranges' in rule1.conditions and 
                'feature_ranges' in rule2.conditions):
                
                ranges1 = rule1.conditions['feature_ranges']
                ranges2 = rule2.conditions['feature_ranges']
                
                # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                combined_ranges = {}
                all_features = set(ranges1.keys()) | set(ranges2.keys())
                
                for feature in all_features:
                    if feature in ranges1 and feature in ranges2:
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
                        min1, max1 = ranges1[feature]
                        min2, max2 = ranges2[feature]
                        
                        combined_min = (min1 + min2) / 2
                        combined_max = (max1 + max2) / 2
                        
                        combined_ranges[feature] = (combined_min, combined_max)
                    elif feature in ranges1:
                        combined_ranges[feature] = ranges1[feature]
                    else:
                        combined_ranges[feature] = ranges2[feature]
                
                # –°–æ–∑–¥–∞–µ–º –ø–æ—Ç–æ–º–∫–∞
                offspring_conditions = {
                    'feature_ranges': combined_ranges,
                    'market_conditions': list(set(
                        rule1.conditions.get('market_conditions', []) +
                        rule2.conditions.get('market_conditions', [])
                    )),
                    'confidence_range': (
                        (rule1.conditions.get('confidence_range', (40, 80))[0] +
                         rule2.conditions.get('confidence_range', (40, 80))[0]) / 2,
                        (rule1.conditions.get('confidence_range', (40, 80))[1] +
                         rule2.conditions.get('confidence_range', (40, 80))[1]) / 2
                    )
                }
                
                offspring_rule = LearningRule(
                    rule_id=f"crossover_{rule1.rule_id}_{rule2.rule_id}_{self.evolution_generation}",
                    rule_name=f"Crossover of {rule1.rule_name} and {rule2.rule_name}",
                    conditions=offspring_conditions,
                    action=random.choice([rule1.action, rule2.action]),
                    priority=(rule1.priority + rule2.priority) / 2,
                    success_history=[],
                    market_adaptability={},
                    evolution_generation=self.evolution_generation,
                    parent_rules=[rule1.rule_id, rule2.rule_id],
                    mutation_history=[]
                )
                
                offspring.append(offspring_rule)
            
            return offspring
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫—Ä–æ—Å—Å–æ–≤–µ—Ä–∞: {e}")
            return []
    
    def apply_rules_to_decision(self, market_data: Dict) -> Dict[str, Any]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª –∫ –ø—Ä–∏–Ω—è—Ç–∏—é —Ä–µ—à–µ–Ω–∏—è"""
        try:
            applicable_rules = []
            
            for rule in self.rules.values():
                if self._rule_matches_data(rule, market_data):
                    applicable_rules.append(rule)
            
            if not applicable_rules:
                return {'decision': 'hold', 'confidence': 50, 'rules_applied': []}
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
            applicable_rules.sort(key=lambda r: r.priority, reverse=True)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª—É—á—à–µ–µ –ø—Ä–∞–≤–∏–ª–æ
            best_rule = applicable_rules[0]
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–≤–∏–ª–∞
            base_confidence = market_data.get('confidence', 50)
            rule_confidence_boost = best_rule.priority * 20  # –ë–æ–Ω—É—Å –æ—Ç –ø—Ä–∞–≤–∏–ª–∞
            
            final_confidence = min(95, base_confidence + rule_confidence_boost)
            
            return {
                'decision': best_rule.action,
                'confidence': final_confidence,
                'rules_applied': [best_rule.rule_id],
                'rule_priority': best_rule.priority,
                'rule_generation': best_rule.evolution_generation
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∞–≤–∏–ª: {e}")
            return {'decision': 'hold', 'confidence': 50, 'rules_applied': []}
    
    def _rule_matches_data(self, rule: LearningRule, market_data: Dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–∞–≤–∏–ª–∞ –¥–∞–Ω–Ω—ã–º"""
        try:
            conditions = rule.conditions
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if 'feature_ranges' in conditions:
                for feature, (min_val, max_val) in conditions['feature_ranges'].items():
                    if feature in market_data:
                        value = market_data[feature]
                        if not (min_val <= value <= max_val):
                            return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
            if 'market_conditions' in conditions:
                market_condition = market_data.get('market_condition', 'NEUTRAL')
                if market_condition not in conditions['market_conditions']:
                    return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
            if 'confidence_range' in conditions:
                confidence = market_data.get('confidence', 50)
                min_conf, max_conf = conditions['confidence_range']
                if not (min_conf <= confidence <= max_conf):
                    return False
            
            return True
            
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–∞–≤–∏–ª–∞: {e}")
            return False
    
    def get_learning_summary(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–¥–∫—É –æ–±—É—á–µ–Ω–∏—è"""
        try:
            total_rules = len(self.rules)
            avg_priority = statistics.mean([r.priority for r in self.rules.values()]) if self.rules else 0
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è–º
            generations = [r.evolution_generation for r in self.rules.values()]
            max_generation = max(generations) if generations else 0
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ –¥–µ–π—Å—Ç–≤–∏—è–º
            actions = [r.action for r in self.rules.values()]
            action_distribution = {action: actions.count(action) for action in set(actions)}
            
            return {
                'total_rules': total_rules,
                'current_generation': self.evolution_generation,
                'max_rule_generation': max_generation,
                'average_priority': avg_priority,
                'action_distribution': action_distribution,
                'learning_approach': 'Universal Rules (not memorization)',
                'generalization_focus': True,
                'evolution_active': total_rules > 1
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–æ–¥–∫–∏: {e}")
            return {}

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã
if __name__ == "__main__":
    learning_system = UniversalLearningSystem()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_data = [
        {'rsi': 35, 'bb_position': 25, 'volume_ratio': 1.2, 'confidence': 65, 'decision': 'buy', 'result': 'win', 'market_condition': 'BULLISH'},
        {'rsi': 40, 'bb_position': 30, 'volume_ratio': 1.1, 'confidence': 70, 'decision': 'buy', 'result': 'win', 'market_condition': 'BULLISH'},
        {'rsi': 32, 'bb_position': 28, 'volume_ratio': 1.3, 'confidence': 68, 'decision': 'buy', 'result': 'win', 'market_condition': 'BULLISH'},
        {'rsi': 75, 'bb_position': 85, 'volume_ratio': 0.8, 'confidence': 45, 'decision': 'sell', 'result': 'loss', 'market_condition': 'BEARISH'},
    ] * 5  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—ã–±–æ—Ä–∫—É
    
    # –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    patterns = learning_system.analyze_market_patterns(test_data)
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(patterns)}")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∞–≤–∏–ª
    rules = learning_system.create_universal_rules(patterns)
    print(f"üß† –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∞–≤–∏–ª: {len(rules)}")
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª
    test_market_data = {'rsi': 37, 'bb_position': 27, 'volume_ratio': 1.15, 'confidence': 66, 'market_condition': 'BULLISH'}
    decision = learning_system.apply_rules_to_decision(test_market_data)
    print(f"üéØ –†–µ—à–µ–Ω–∏–µ: {decision}")
    
    # –°–≤–æ–¥–∫–∞ –æ–±—É—á–µ–Ω–∏—è
    summary = learning_system.get_learning_summary()
    print(f"üìã –°–≤–æ–¥–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {summary}")
    
    print("‚úÖ UniversalLearningSystem –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∞")

