#!/usr/bin/env python3
"""
üßπ –°–ò–°–¢–ï–ú–ê –ê–í–¢–û–û–ß–ò–°–¢–ö–ò –õ–û–ì–û–í –ò –ë–ê–ó–´ –î–ê–ù–ù–´–•
==========================================

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—á–∏—â–∞–µ—Ç:
- –°—Ç–∞—Ä—ã–µ –ª–æ–≥–∏ (>7 –¥–Ω–µ–π)
- –°—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –≤ –ë–î (>30 –¥–Ω–µ–π –¥–ª—è market_data, >90 –¥–Ω–µ–π –¥–ª—è trade_decisions)
- –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏ –∫—ç—à–∏
"""

import os
import sys
import sqlite3
import logging
from pathlib import Path
from datetime import datetime, timedelta
import shutil

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s][%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class AutoCleanupSystem:
    """üßπ –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∏"""
    
    def __init__(self):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å
        if Path("/opt/bot").exists():
            self.base_dir = Path("/opt/bot")
        else:
            self.base_dir = Path(__file__).parent
        
        self.logs_dir = self.base_dir / "logs"
        self.data_dir = self.base_dir / "data"
        self.cache_dir = self.data_dir / "cache"
        self.db_path = self.base_dir / "trading_data.db"
        if not self.db_path.exists():
            self.db_path = self.data_dir / "trading_data.db"
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—á–∏—Å—Ç–∫–∏
        self.log_retention_days = 7  # –õ–æ–≥–∏ —Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π
        self.cache_retention_hours = 24  # –ö—ç—à —Å—Ç–∞—Ä—à–µ 24 —á–∞—Å–æ–≤
        self.market_data_retention_days = 30  # –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
        self.trade_decisions_retention_days = 90  # –¢–æ—Ä–≥–æ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è —Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π (–≤–∞–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
        self.temp_files_retention_hours = 12  # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ 12 —á–∞—Å–æ–≤
        
        self.stats = {
            'logs_deleted': 0,
            'logs_freed_mb': 0.0,
            'cache_deleted': 0,
            'cache_freed_mb': 0.0,
            'db_records_deleted': 0,
            'temp_files_deleted': 0,
            'temp_freed_mb': 0.0,
            'total_freed_mb': 0.0
        }
    
    def cleanup_logs(self) -> bool:
        """üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ –∏ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤"""
        logger.info("\n" + "="*60)
        logger.info("üßπ –û–ß–ò–°–¢–ö–ê –°–¢–ê–†–´–• –õ–û–ì–û–í")
        logger.info("="*60)
        
        try:
            if not self.logs_dir.exists():
                logger.warning("  ‚ö†Ô∏è –ü–∞–ø–∫–∞ logs –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
            
            cutoff_date = datetime.now() - timedelta(days=self.log_retention_days)
            cutoff_timestamp = cutoff_date.timestamp()
            
            logs_deleted = 0
            freed_size = 0
            
            # 1. –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ .log —Ñ–∞–π–ª—ã (>7 –¥–Ω–µ–π)
            for log_file in self.logs_dir.rglob("*.log"):
                try:
                    if log_file.is_file() and log_file.stat().st_mtime < cutoff_timestamp:
                        size = log_file.stat().st_size
                        log_file.unlink()
                        logs_deleted += 1
                        freed_size += size
                        logger.debug(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π: {log_file.name} ({size / 1024 / 1024:.1f} MB)")
                except Exception as e:
                    logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {log_file}: {e}")
            
            # 2. –£–¥–∞–ª—è–µ–º –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã (>500MB) —Å—Ç–∞—Ä—à–µ 1 –¥–Ω—è
            large_cutoff = datetime.now() - timedelta(days=1)
            large_cutoff_timestamp = large_cutoff.timestamp()
            for log_file in self.logs_dir.rglob("*.log"):
                try:
                    if log_file.is_file():
                        size = log_file.stat().st_size
                        # –ï—Å–ª–∏ —Ñ–∞–π–ª >500MB –∏ —Å—Ç–∞—Ä—à–µ 1 –¥–Ω—è
                        if size > 500 * 1024 * 1024 and log_file.stat().st_mtime < large_cutoff_timestamp:
                            log_file.unlink()
                            logs_deleted += 1
                            freed_size += size
                            logger.info(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª: {log_file.name} ({size / 1024 / 1024:.1f} MB)")
                        # –ï—Å–ª–∏ —Ñ–∞–π–ª >2GB (–∫—Ä–∏—Ç–∏—á–Ω–æ) - —É–¥–∞–ª—è–µ–º –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞
                        elif size > 2 * 1024 * 1024 * 1024:
                            log_file.unlink()
                            logs_deleted += 1
                            freed_size += size
                            logger.warning(f"  ‚ö†Ô∏è –£–¥–∞–ª–µ–Ω –∫—Ä–∏—Ç–∏—á–Ω–æ –±–æ–ª—å—à–æ–π —Ñ–∞–π–ª: {log_file.name} ({size / 1024 / 1024 / 1024:.2f} GB)")
                except Exception as e:
                    logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {log_file}: {e}")
            
            # 3. –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Ä–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ª–æ–≥–æ–≤ (—Å –¥–ª–∏–Ω–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ —Å –¥–∞—Ç–∞–º–∏)
            for log_file in self.logs_dir.rglob("*2025*.log"):
                try:
                    if log_file.is_file() and log_file.stat().st_mtime < large_cutoff_timestamp:
                        size = log_file.stat().st_size
                        # –†–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ª–æ–≥–∏ —Å –¥–∞—Ç–∞–º–∏ –≤ –∏–º–µ–Ω–∏ —Å—Ç–∞—Ä—à–µ 1 –¥–Ω—è
                        if "2025" in log_file.name and size > 10 * 1024 * 1024:  # >10MB
                            log_file.unlink()
                            logs_deleted += 1
                            freed_size += size
                            logger.debug(f"  üóëÔ∏è –£–¥–∞–ª–µ–Ω —Ä–æ—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π: {log_file.name} ({size / 1024 / 1024:.1f} MB)")
                except Exception as e:
                    logger.debug(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {log_file}: {e}")
            
            self.stats['logs_deleted'] = logs_deleted
            self.stats['logs_freed_mb'] = round(freed_size / (1024**2), 2)
            
            if logs_deleted > 0:
                logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ –ª–æ–≥–æ–≤: {logs_deleted} —Ñ–∞–π–ª–æ–≤")
                logger.info(f"  üíæ –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ: {self.stats['logs_freed_mb']:.2f} MB")
            else:
                logger.info(f"  ‚úÖ –°—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤—Å–µ —Å–≤–µ–∂–µ–µ {self.log_retention_days} –¥–Ω–µ–π)")
            
            return True
            
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ª–æ–≥–æ–≤: {e}")
            return False
    
    def cleanup_cache(self) -> bool:
        """üóÇÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∫—ç—à–µ–π"""
        logger.info("\n" + "="*60)
        logger.info("üóÇÔ∏è –û–ß–ò–°–¢–ö–ê –°–¢–ê–†–´–• –ö–≠–®–ï–ô")
        logger.info("="*60)
        
        try:
            if not self.cache_dir.exists():
                logger.warning("  ‚ö†Ô∏è –ü–∞–ø–∫–∞ cache –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
            
            cutoff_date = datetime.now() - timedelta(hours=self.cache_retention_hours)
            cutoff_timestamp = cutoff_date.timestamp()
            
            cache_deleted = 0
            freed_size = 0
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –∫—ç—à–∞
            for cache_file in self.cache_dir.rglob("*"):
                try:
                    if cache_file.is_file() and cache_file.stat().st_mtime < cutoff_timestamp:
                        size = cache_file.stat().st_size
                        cache_file.unlink()
                        cache_deleted += 1
                        freed_size += size
                except Exception as e:
                    logger.debug(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {cache_file}: {e}")
            
            self.stats['cache_deleted'] = cache_deleted
            self.stats['cache_freed_mb'] = round(freed_size / (1024**2), 2)
            
            if cache_deleted > 0:
                logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ –∫—ç—à–µ–π: {cache_deleted} —Ñ–∞–π–ª–æ–≤")
                logger.info(f"  üíæ –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ: {self.stats['cache_freed_mb']:.2f} MB")
            else:
                logger.info(f"  ‚úÖ –°—Ç–∞—Ä—ã—Ö –∫—ç—à–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤—Å–µ —Å–≤–µ–∂–µ–µ {self.cache_retention_hours} —á–∞—Å–æ–≤)")
            
            return True
            
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")
            return False
    
    def cleanup_database(self) -> bool:
        """üíæ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("\n" + "="*60)
        logger.info("üíæ –û–ß–ò–°–¢–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•")
        logger.info("="*60)
        
        try:
            if not self.db_path.exists():
                logger.warning("  ‚ö†Ô∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
            
            conn = sqlite3.connect(str(self.db_path))
            cursor = conn.cursor()
            
            total_deleted = 0
            
            # 1. –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö market_data (—Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π)
            try:
                cutoff_date = datetime.now() - timedelta(days=self.market_data_retention_days)
                cutoff_str = cutoff_date.strftime('%Y-%m-%d %H:%M:%S')
                
                cursor.execute("""
                    SELECT COUNT(*) FROM market_data
                    WHERE datetime(timestamp) < datetime(?)
                """, (cutoff_str,))
                
                count_before = cursor.fetchone()[0]
                
                if count_before > 0:
                    cursor.execute("""
                        DELETE FROM market_data
                        WHERE datetime(timestamp) < datetime(?)
                    """, (cutoff_str,))
                    
                    deleted_market = cursor.rowcount
                    total_deleted += deleted_market
                    logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö market_data: {deleted_market} –∑–∞–ø–∏—Å–µ–π (—Å—Ç–∞—Ä—à–µ {self.market_data_retention_days} –¥–Ω–µ–π)")
                else:
                    logger.info(f"  ‚úÖ –°—Ç–∞—Ä—ã—Ö market_data –Ω–µ –Ω–∞–π–¥–µ–Ω–æ (–≤—Å–µ —Å–≤–µ–∂–µ–µ {self.market_data_retention_days} –¥–Ω–µ–π)")
                    
            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ market_data: {e}")
            
            # 2. –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö trade_decisions (—Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Å–¥–µ–ª–∫–∏)
            try:
                cutoff_date = datetime.now() - timedelta(days=self.trade_decisions_retention_days)
                cutoff_str = cutoff_date.strftime('%Y-%m-%d %H:%M:%S')
                
                # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ—É–¥–∞—á–Ω—ã–µ —Å–¥–µ–ª–∫–∏ —Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π, —É—Å–ø–µ—à–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–ª—å—à–µ
                cursor.execute("""
                    SELECT COUNT(*) FROM trade_decisions
                    WHERE datetime(timestamp) < datetime(?)
                    AND (result = 'loss' OR result IS NULL OR result = '')
                """, (cutoff_str,))
                
                count_before = cursor.fetchone()[0]
                
                if count_before > 0:
                    cursor.execute("""
                        DELETE FROM trade_decisions
                        WHERE datetime(timestamp) < datetime(?)
                        AND (result = 'loss' OR result IS NULL OR result = '')
                    """, (cutoff_str,))
                    
                    deleted_trades = cursor.rowcount
                    total_deleted += deleted_trades
                    logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö trade_decisions (loss): {deleted_trades} –∑–∞–ø–∏—Å–µ–π (—Å—Ç–∞—Ä—à–µ {self.trade_decisions_retention_days} –¥–Ω–µ–π)")
                else:
                    logger.info(f"  ‚úÖ –°—Ç–∞—Ä—ã—Ö trade_decisions (loss) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                
                # –¢–∞–∫–∂–µ —É–¥–∞–ª—è–µ–º –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã–µ —É—Å–ø–µ—à–Ω—ã–µ —Å–¥–µ–ª–∫–∏ (—Å—Ç–∞—Ä—à–µ 180 –¥–Ω–µ–π)
                old_cutoff = datetime.now() - timedelta(days=180)
                old_cutoff_str = old_cutoff.strftime('%Y-%m-%d %H:%M:%S')
                
                cursor.execute("""
                    SELECT COUNT(*) FROM trade_decisions
                    WHERE datetime(timestamp) < datetime(?)
                """, (old_cutoff_str,))
                
                count_very_old = cursor.fetchone()[0]
                
                if count_very_old > 0:
                    cursor.execute("""
                        DELETE FROM trade_decisions
                        WHERE datetime(timestamp) < datetime(?)
                    """, (old_cutoff_str,))
                    
                    deleted_old = cursor.rowcount
                    total_deleted += deleted_old
                    logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã—Ö trade_decisions (–≤—Å–µ): {deleted_old} –∑–∞–ø–∏—Å–µ–π (—Å—Ç–∞—Ä—à–µ 180 –¥–Ω–µ–π)")
                    
            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ trade_decisions: {e}")
            
            # 3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ë–î (VACUUM)
            try:
                logger.info("  üîÑ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
                cursor.execute("VACUUM")
                logger.info("  ‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            except Exception as e:
                logger.warning(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
            
            conn.commit()
            conn.close()
            
            self.stats['db_records_deleted'] = total_deleted
            
            if total_deleted > 0:
                logger.info(f"\n  ‚úÖ –ò–¢–û–ì–û —É–¥–∞–ª–µ–Ω–æ –∏–∑ –ë–î: {total_deleted} –∑–∞–ø–∏—Å–µ–π")
            else:
                logger.info(f"\n  ‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —á–∏—Å—Ç–∞—è, —É–¥–∞–ª—è—Ç—å –Ω–µ—á–µ–≥–æ")
            
            return True
            
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False
    
    def cleanup_temp_files(self) -> bool:
        """üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        logger.info("\n" + "="*60)
        logger.info("üóëÔ∏è –û–ß–ò–°–¢–ö–ê –í–†–ï–ú–ï–ù–ù–´–• –§–ê–ô–õ–û–í")
        logger.info("="*60)
        
        try:
            cutoff_date = datetime.now() - timedelta(hours=self.temp_files_retention_hours)
            cutoff_timestamp = cutoff_date.timestamp()
            
            temp_patterns = ['*.tmp', '*.temp', '*~', '*.swp', '*.bak']
            temp_files_deleted = 0
            freed_size = 0
            
            for pattern in temp_patterns:
                for temp_file in self.base_dir.rglob(pattern):
                    try:
                        if temp_file.is_file() and temp_file.stat().st_mtime < cutoff_timestamp:
                            size = temp_file.stat().st_size
                            temp_file.unlink()
                            temp_files_deleted += 1
                            freed_size += size
                    except Exception as e:
                        logger.debug(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {temp_file}: {e}")
            
            # –£–¥–∞–ª—è–µ–º __pycache__
            pycache_deleted = 0
            for pycache_dir in self.base_dir.rglob('__pycache__'):
                try:
                    if pycache_dir.is_dir():
                        size = sum(f.stat().st_size for f in pycache_dir.rglob('*') if f.is_file())
                        shutil.rmtree(pycache_dir)
                        pycache_deleted += 1
                        freed_size += size
                except Exception as e:
                    logger.debug(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è {pycache_dir}: {e}")
            
            self.stats['temp_files_deleted'] = temp_files_deleted + pycache_deleted
            self.stats['temp_freed_mb'] = round(freed_size / (1024**2), 2)
            
            if self.stats['temp_files_deleted'] > 0:
                logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {temp_files_deleted} —Ñ–∞–π–ª–æ–≤, {pycache_deleted} __pycache__")
                logger.info(f"  üíæ –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ: {self.stats['temp_freed_mb']:.2f} MB")
            else:
                logger.info(f"  ‚úÖ –í—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
            return True
            
        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")
            return False
    
    def run_full_cleanup(self):
        """üöÄ –ü–æ–ª–Ω–∞—è –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞"""
        logger.info("\n" + "="*60)
        logger.info("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ô –ê–í–¢–û–û–ß–ò–°–¢–ö–ò")
        logger.info("="*60)
        logger.info(f"–í—Ä–µ–º—è –∑–∞–ø—É—Å–∫–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –≤–∏–¥—ã –æ—á–∏—Å—Ç–∫–∏
        self.cleanup_logs()
        self.cleanup_cache()
        self.cleanup_database()
        self.cleanup_temp_files()
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–Ω–æ–µ –º–µ—Å—Ç–æ
        self.stats['total_freed_mb'] = (
            self.stats['logs_freed_mb'] +
            self.stats['cache_freed_mb'] +
            self.stats['temp_freed_mb']
        )
        
        # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        logger.info("\n" + "="*60)
        logger.info("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ê–í–¢–û–û–ß–ò–°–¢–ö–ò")
        logger.info("="*60)
        logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ –ª–æ–≥–æ–≤: {self.stats['logs_deleted']} —Ñ–∞–π–ª–æ–≤ ({self.stats['logs_freed_mb']:.2f} MB)")
        logger.info(f"üóÇÔ∏è –£–¥–∞–ª–µ–Ω–æ –∫—ç—à–µ–π: {self.stats['cache_deleted']} —Ñ–∞–π–ª–æ–≤ ({self.stats['cache_freed_mb']:.2f} MB)")
        logger.info(f"üíæ –£–¥–∞–ª–µ–Ω–æ –∏–∑ –ë–î: {self.stats['db_records_deleted']} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö: {self.stats['temp_files_deleted']} –æ–±—ä–µ–∫—Ç–æ–≤ ({self.stats['temp_freed_mb']:.2f} MB)")
        logger.info(f"\nüíæ –í–°–ï–ì–û –û–°–í–û–ë–û–ñ–î–ï–ù–û: {self.stats['total_freed_mb']:.2f} MB")
        logger.info("="*60)
        
        return self.stats


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    cleanup = AutoCleanupSystem()
    cleanup.run_full_cleanup()


if __name__ == "__main__":
    main()

