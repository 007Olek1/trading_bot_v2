#!/usr/bin/env python3
"""
üè• –ö–û–ú–ü–õ–ï–ö–°–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ó–î–û–†–û–í–¨–Ø –°–ï–†–í–ï–†–ê
========================================

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
1. –ú–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ –∏ —É–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞
2. –í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
3. OpenAI API –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
4. –ü—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å –±–æ—Ç–∞ (PnL, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
"""

import os
import sys
import shutil
import subprocess
import json
import sqlite3
from pathlib import Path
from datetime import datetime, timedelta
import logging
from typing import Dict, List, Any, Optional
import requests

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s][%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


class ServerHealthCheck:
    """üè• –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞"""
    
    def __init__(self):
        self.results = {
            'disk_space': {},
            'cleanup': {},
            'libraries': {},
            'openai_api': {},
            'profitability': {},
            'overall': 'PENDING'
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å
        if Path("/opt/bot").exists():
            self.base_dir = Path("/opt/bot")
            logger.info("üìÇ –†–∞–±–æ—Ç–∞–µ–º –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ: /opt/bot")
        else:
            self.base_dir = Path(__file__).parent
            logger.info(f"üìÇ –†–∞–±–æ—Ç–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ: {self.base_dir}")
        
        self.data_dir = self.base_dir / "data"
        self.logs_dir = self.base_dir / "logs"
        self.cache_dir = self.data_dir / "cache"
    
    def check_disk_space(self) -> Dict[str, Any]:
        """üíæ –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ"""
        logger.info("\n" + "="*60)
        logger.info("üíæ –ü–†–û–í–ï–†–ö–ê –ú–ï–°–¢–ê –ù–ê –î–ò–°–ö–ï")
        logger.info("="*60)
        
        results = {}
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∏—Å–∫–∞
            stat = shutil.disk_usage(self.base_dir)
            
            total_gb = stat.total / (1024**3)
            used_gb = stat.used / (1024**3)
            free_gb = stat.free / (1024**3)
            used_percent = (stat.used / stat.total) * 100
            
            results = {
                'total_gb': round(total_gb, 2),
                'used_gb': round(used_gb, 2),
                'free_gb': round(free_gb, 2),
                'used_percent': round(used_percent, 2),
                'status': '‚úÖ' if used_percent < 80 else '‚ö†Ô∏è' if used_percent < 90 else '‚ùå'
            }
            
            logger.info(f"  üìä –í—Å–µ–≥–æ: {total_gb:.2f} GB")
            logger.info(f"  üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {used_gb:.2f} GB ({used_percent:.1f}%)")
            logger.info(f"  üìä –°–≤–æ–±–æ–¥–Ω–æ: {free_gb:.2f} GB")
            logger.info(f"  {results['status']} –°—Ç–∞—Ç—É—Å: {'–ù–æ—Ä–º–∞' if used_percent < 80 else '–í–Ω–∏–º–∞–Ω–∏–µ' if used_percent < 90 else '–ö—Ä–∏—Ç–∏—á–Ω–æ'}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –ø–∞–ø–æ–∫ –±–æ—Ç–∞
            if self.base_dir.exists():
                bot_size = sum(f.stat().st_size for f in self.base_dir.rglob('*') if f.is_file())
                bot_size_gb = bot_size / (1024**3)
                results['bot_size_gb'] = round(bot_size_gb, 2)
                logger.info(f"  üìÅ –†–∞–∑–º–µ—Ä –ø–∞–ø–∫–∏ –±–æ—Ç–∞: {bot_size_gb:.2f} GB")
                
                # –†–∞–∑–º–µ—Ä—ã –ø–æ–¥–ø–∞–ø–æ–∫
                for subdir in ['data', 'logs']:
                    subdir_path = self.base_dir / subdir
                    if subdir_path.exists():
                        subdir_size = sum(f.stat().st_size for f in subdir_path.rglob('*') if f.is_file())
                        subdir_size_mb = subdir_size / (1024**2)
                        results[f'{subdir}_size_mb'] = round(subdir_size_mb, 2)
                        logger.info(f"    üìÇ {subdir}/: {subdir_size_mb:.2f} MB")
        
        except Exception as e:
            results = {'error': str(e), 'status': '‚ùå'}
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∏—Å–∫–∞: {e}")
        
        self.results['disk_space'] = results
        return results
    
    def cleanup_junk(self) -> Dict[str, Any]:
        """üßπ –£–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞"""
        logger.info("\n" + "="*60)
        logger.info("üßπ –£–ë–û–†–ö–ê –ú–£–°–û–†–ê")
        logger.info("="*60)
        
        results = {
            'cleaned': {},
            'freed_mb': 0,
            'total_cleaned': 0
        }
        
        try:
            # 1. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤ (>7 –¥–Ω–µ–π)
            if self.logs_dir.exists():
                log_files = list(self.logs_dir.rglob('*.log'))
                old_logs = []
                cutoff_date = datetime.now() - timedelta(days=7)
                freed_size = 0
                
                for log_file in log_files:
                    try:
                        if log_file.stat().st_mtime < cutoff_date.timestamp():
                            size = log_file.stat().st_size
                            log_file.unlink()
                            old_logs.append(str(log_file))
                            freed_size += size
                    except:
                        pass
                
                results['cleaned']['old_logs'] = {
                    'count': len(old_logs),
                    'freed_mb': round(freed_size / (1024**2), 2)
                }
                logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥–æ–≤: {len(old_logs)} —Ñ–∞–π–ª–æ–≤, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {freed_size / (1024**2):.2f} MB")
            
            # 2. –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ (>24 —á–∞—Å–æ–≤)
            if self.cache_dir.exists():
                cache_files = list(self.cache_dir.rglob('*'))
                old_cache = []
                cutoff_date = datetime.now() - timedelta(hours=24)
                freed_size = 0
                
                for cache_file in cache_files:
                    try:
                        if cache_file.is_file() and cache_file.stat().st_mtime < cutoff_date.timestamp():
                            size = cache_file.stat().st_size
                            cache_file.unlink()
                            old_cache.append(str(cache_file))
                            freed_size += size
                    except:
                        pass
                
                results['cleaned']['old_cache'] = {
                    'count': len(old_cache),
                    'freed_mb': round(freed_size / (1024**2), 2)
                }
                logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –∫—ç—à–µ–π: {len(old_cache)} —Ñ–∞–π–ª–æ–≤, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {freed_size / (1024**2):.2f} MB")
            
            # 3. –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            temp_patterns = ['*.tmp', '*.temp', '*~', '*.swp', '*.bak']
            temp_files = []
            freed_size = 0
            
            for pattern in temp_patterns:
                for temp_file in self.base_dir.rglob(pattern):
                    try:
                        if temp_file.is_file():
                            size = temp_file.stat().st_size
                            temp_file.unlink()
                            temp_files.append(str(temp_file))
                            freed_size += size
                    except:
                        pass
            
            results['cleaned']['temp_files'] = {
                'count': len(temp_files),
                'freed_mb': round(freed_size / (1024**2), 2)
            }
            logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(temp_files)} —Ñ–∞–π–ª–æ–≤, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {freed_size / (1024**2):.2f} MB")
            
            # 4. –£–¥–∞–ª–µ–Ω–∏–µ __pycache__
            pycache_dirs = []
            freed_size = 0
            
            for pycache_dir in self.base_dir.rglob('__pycache__'):
                try:
                    if pycache_dir.is_dir():
                        size = sum(f.stat().st_size for f in pycache_dir.rglob('*') if f.is_file())
                        shutil.rmtree(pycache_dir)
                        pycache_dirs.append(str(pycache_dir))
                        freed_size += size
                except:
                    pass
            
            results['cleaned']['pycache'] = {
                'count': len(pycache_dirs),
                'freed_mb': round(freed_size / (1024**2), 2)
            }
            logger.info(f"  ‚úÖ –£–¥–∞–ª–µ–Ω–æ __pycache__: {len(pycache_dirs)} –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {freed_size / (1024**2):.2f} MB")
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–Ω–æ–µ –º–µ—Å—Ç–æ
            total_freed = sum(
                item.get('freed_mb', 0) for item in results['cleaned'].values()
                if isinstance(item, dict)
            )
            results['freed_mb'] = round(total_freed, 2)
            results['total_cleaned'] = sum(
                item.get('count', 0) for item in results['cleaned'].values()
                if isinstance(item, dict)
            )
            results['status'] = '‚úÖ'
            
            logger.info(f"\n  üéâ –ò–¢–û–ì–û: –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ {total_freed:.2f} MB, —É–¥–∞–ª–µ–Ω–æ {results['total_cleaned']} –æ–±—ä–µ–∫—Ç–æ–≤")
        
        except Exception as e:
            results['error'] = str(e)
            results['status'] = '‚ùå'
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ —É–±–æ—Ä–∫–∏: {e}")
        
        self.results['cleanup'] = results
        return results
    
    def check_libraries(self) -> Dict[str, Any]:
        """üìö –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"""
        logger.info("\n" + "="*60)
        logger.info("üìö –ü–†–û–í–ï–†–ö–ê –ë–ò–ë–õ–ò–û–¢–ï–ö")
        logger.info("="*60)
        
        results = {
            'required': {},
            'missing': [],
            'outdated': [],
            'status': '‚úÖ'
        }
        
        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
        required_libs = {
            'ccxt': 'ccxt',
            'pandas': 'pandas',
            'numpy': 'numpy',
            'scikit-learn': 'sklearn',
            'tensorflow': 'tensorflow',
            'requests': 'requests',
            'python-telegram-bot': 'telegram',
            'pybit': 'pybit',
            'asyncio': 'asyncio',
            'pytz': 'pytz',
            'sqlite3': 'sqlite3',
        }
        
        for lib_name, import_name in required_libs.items():
            try:
                if import_name == 'sqlite3':
                    import sqlite3
                    version = sqlite3.sqlite_version
                elif import_name == 'asyncio':
                    import asyncio
                    version = 'built-in'
                else:
                    module = __import__(import_name)
                    version = getattr(module, '__version__', 'unknown')
                
                results['required'][lib_name] = {
                    'status': '‚úÖ',
                    'version': version,
                    'installed': True
                }
                logger.info(f"  ‚úÖ {lib_name}: {version}")
                
            except ImportError:
                results['required'][lib_name] = {
                    'status': '‚ùå',
                    'installed': False
                }
                results['missing'].append(lib_name)
                logger.error(f"  ‚ùå {lib_name}: –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù")
                results['status'] = '‚ùå'
            except Exception as e:
                results['required'][lib_name] = {
                    'status': '‚ö†Ô∏è',
                    'error': str(e)
                }
                logger.warning(f"  ‚ö†Ô∏è {lib_name}: –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ - {e}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
        optional_libs = {
            'openai': 'openai',
            'joblib': 'joblib',
            'matplotlib': 'matplotlib',
        }
        
        for lib_name, import_name in optional_libs.items():
            try:
                module = __import__(import_name)
                version = getattr(module, '__version__', 'unknown')
                logger.info(f"  ‚úÖ {lib_name} (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ): {version}")
            except ImportError:
                logger.warning(f"  ‚ö†Ô∏è {lib_name} (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ): –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù")
        
        if results['missing']:
            logger.error(f"\n  ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {', '.join(results['missing'])}")
        else:
            logger.info(f"\n  ‚úÖ –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        
        self.results['libraries'] = results
        return results
    
    def check_openai_api(self) -> Dict[str, Any]:
        """ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ OpenAI API"""
        logger.info("\n" + "="*60)
        logger.info("ü§ñ –ü–†–û–í–ï–†–ö–ê OPENAI API")
        logger.info("="*60)
        
        results = {
            'api_key_set': False,
            'connection': False,
            'status': '‚ùå'
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ API –∫–ª—é—á–∞
            api_key = os.getenv('OPENAI_API_KEY')
            
            if not api_key:
                # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ .env —Ñ–∞–π–ª–∞
                env_file = self.base_dir / ".env"
                if env_file.exists():
                    with open(env_file, 'r') as f:
                        for line in f:
                            if line.startswith('OPENAI_API_KEY='):
                                api_key = line.split('=', 1)[1].strip().strip('"\'')
                                break
            
            if api_key:
                results['api_key_set'] = True
                logger.info("  ‚úÖ OPENAI_API_KEY –Ω–∞–π–¥–µ–Ω")
                
                # –ü—Ä–æ–±—É–µ–º –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API
                try:
                    import openai
                    openai.api_key = api_key
                    
                    # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–ø—Ä–æ—Å—Ç–æ–π, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å —Ç–æ–∫–µ–Ω—ã)
                    response = requests.get(
                        'https://api.openai.com/v1/models',
                        headers={'Authorization': f'Bearer {api_key}'},
                        timeout=5
                    )
                    
                    if response.status_code == 200:
                        results['connection'] = True
                        results['status'] = '‚úÖ'
                        logger.info("  ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI API —É—Å–ø–µ—à–Ω–æ")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
                        models_data = response.json()
                        model_count = len(models_data.get('data', []))
                        logger.info(f"  üìä –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {model_count}")
                    else:
                        logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                        results['error'] = f"HTTP {response.status_code}"
                except ImportError:
                    logger.warning("  ‚ö†Ô∏è –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ openai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")
                    results['error'] = "Library not installed"
                except Exception as e:
                    logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
                    results['error'] = str(e)
            else:
                logger.warning("  ‚ö†Ô∏è OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")
                results['error'] = "API key not found"
        
        except Exception as e:
            results['error'] = str(e)
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ OpenAI API: {e}")
        
        self.results['openai_api'] = results
        return results
    
    def check_profitability(self) -> Dict[str, Any]:
        """üí∞ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏"""
        logger.info("\n" + "="*60)
        logger.info("üí∞ –ü–†–û–í–ï–†–ö–ê –ü–†–ò–ë–´–õ–¨–ù–û–°–¢–ò")
        logger.info("="*60)
        
        results = {
            'total_pnl': 0.0,
            'total_trades': 0,
            'winning_trades': 0,
            'losing_trades': 0,
            'win_rate': 0.0,
            'avg_profit': 0.0,
            'avg_loss': 0.0,
            'status': '‚ö†Ô∏è'
        }
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            db_path = self.base_dir / "data" / "trading_data.db"
            if not db_path.exists():
                db_path = self.base_dir / "trading_data.db"
            
            if db_path.exists():
                conn = sqlite3.connect(str(db_path))
                cursor = conn.cursor()
                
                # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ trade_decisions
                cursor.execute("""
                    SELECT 
                        COUNT(*) as total,
                        SUM(CASE WHEN result = 'win' THEN 1 ELSE 0 END) as wins,
                        SUM(CASE WHEN result = 'loss' THEN 1 ELSE 0 END) as losses,
                        AVG(CASE WHEN result = 'win' AND pnl_percent IS NOT NULL THEN pnl_percent ELSE NULL END) as avg_win,
                        AVG(CASE WHEN result = 'loss' AND pnl_percent IS NOT NULL THEN pnl_percent ELSE NULL END) as avg_loss,
                        SUM(CASE WHEN pnl_percent IS NOT NULL THEN pnl_percent ELSE 0 END) as total_pnl_pct
                    FROM trade_decisions
                    WHERE result IN ('win', 'loss')
                """)
                
                row = cursor.fetchone()
                if row and row[0]:
                    total, wins, losses, avg_win, avg_loss, total_pnl_pct = row
                    
                    results['total_trades'] = total or 0
                    results['winning_trades'] = wins or 0
                    results['losing_trades'] = losses or 0
                    results['win_rate'] = round((wins / total * 100) if total > 0 else 0, 2)
                    results['avg_profit'] = round(avg_win if avg_win else 0, 2)
                    results['avg_loss'] = round(avg_loss if avg_loss else 0, 2)
                    results['total_pnl_percent'] = round(total_pnl_pct if total_pnl_pct else 0, 2)
                    
                    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –ø—Ä–∏–±—ã–ª—å –≤ USD (–ø—Ä–∏–º–µ—Ä–Ω–æ, –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–∑–∏—Ü–∏–π $25)
                    position_size = 25.0
                    results['estimated_total_pnl_usd'] = round(
                        (total_pnl_pct / 100) * position_size if total_pnl_pct else 0, 2
                    )
                    
                    logger.info(f"  üìä –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {total}")
                    logger.info(f"  ‚úÖ –í—ã–∏–≥—Ä—ã—à–Ω—ã—Ö: {wins} ({results['win_rate']}%)")
                    logger.info(f"  ‚ùå –ü—Ä–æ–∏–≥—Ä—ã—à–Ω—ã—Ö: {losses}")
                    logger.info(f"  üíµ –°—Ä–µ–¥–Ω—è—è –ø—Ä–∏–±—ã–ª—å: +{results['avg_profit']:.2f}%")
                    logger.info(f"  üí∏ –°—Ä–µ–¥–Ω–∏–π —É–±—ã—Ç–æ–∫: {results['avg_loss']:.2f}%")
                    logger.info(f"  üìà –û–±—â–∏–π PnL: {results['total_pnl_percent']:.2f}% (‚âà${results['estimated_total_pnl_usd']:.2f})")
                    
                    if results['win_rate'] > 50 and results['estimated_total_pnl_usd'] > 0:
                        results['status'] = '‚úÖ'
                    elif results['win_rate'] > 40:
                        results['status'] = '‚ö†Ô∏è'
                else:
                    logger.warning("  ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Å–¥–µ–ª–∫–∞—Ö –≤ –±–∞–∑–µ")
                    results['status'] = '‚ö†Ô∏è'
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–¥–µ–ª–∫–∏
                cursor.execute("""
                    SELECT symbol, decision, result, pnl_percent, timestamp
                    FROM trade_decisions
                    WHERE result IN ('win', 'loss')
                    ORDER BY timestamp DESC
                    LIMIT 5
                """)
                
                recent_trades = cursor.fetchall()
                if recent_trades:
                    logger.info(f"\n  üìã –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–¥–µ–ª–æ–∫:")
                    for trade in recent_trades:
                        symbol, decision, result, pnl, ts = trade
                        emoji = '‚úÖ' if result == 'win' else '‚ùå'
                        logger.info(f"    {emoji} {symbol} {decision.upper()} | {result} | PnL: {pnl if pnl else 'N/A'}% | {ts}")
                
                conn.close()
            else:
                logger.warning("  ‚ö†Ô∏è –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                results['error'] = "Database not found"
                results['status'] = '‚ö†Ô∏è'
        
        except Exception as e:
            results['error'] = str(e)
            results['status'] = '‚ùå'
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏: {e}")
        
        self.results['profitability'] = results
        return results
    
    def generate_report(self) -> str:
        """üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        logger.info("\n" + "="*60)
        logger.info("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
        logger.info("="*60)
        
        report_lines = []
        report_lines.append("="*60)
        report_lines.append("üè• –ö–û–ú–ü–õ–ï–ö–°–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ó–î–û–†–û–í–¨–Ø –°–ï–†–í–ï–†–ê")
        report_lines.append("="*60)
        report_lines.append(f"\n–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"–°–µ—Ä–≤–µ—Ä: {self.base_dir}")
        report_lines.append("\n" + "-"*60)
        
        # –î–∏—Å–∫
        disk = self.results.get('disk_space', {})
        if disk.get('status'):
            status = disk['status']
            report_lines.append(f"\nüíæ –ú–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ: {status}")
            if 'used_percent' in disk:
                report_lines.append(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {disk['used_percent']:.1f}%")
                report_lines.append(f"   –°–≤–æ–±–æ–¥–Ω–æ: {disk.get('free_gb', 0):.2f} GB")
        
        # –£–±–æ—Ä–∫–∞
        cleanup = self.results.get('cleanup', {})
        if cleanup.get('status'):
            status = cleanup['status']
            report_lines.append(f"\nüßπ –£–±–æ—Ä–∫–∞: {status}")
            if 'freed_mb' in cleanup:
                report_lines.append(f"   –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ: {cleanup['freed_mb']:.2f} MB")
                report_lines.append(f"   –£–¥–∞–ª–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {cleanup.get('total_cleaned', 0)}")
        
        # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏
        libs = self.results.get('libraries', {})
        if libs.get('status'):
            status = libs['status']
            report_lines.append(f"\nüìö –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏: {status}")
            if libs.get('missing'):
                report_lines.append(f"   –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç: {', '.join(libs['missing'])}")
            else:
                report_lines.append(f"   –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        
        # OpenAI
        openai_result = self.results.get('openai_api', {})
        status = openai_result.get('status', '‚ö†Ô∏è')
        report_lines.append(f"\nü§ñ OpenAI API: {status}")
        if openai_result.get('api_key_set'):
            report_lines.append(f"   API –∫–ª—é—á: ‚úÖ –ù–∞–π–¥–µ–Ω")
        else:
            report_lines.append(f"   API –∫–ª—é—á: ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω")
        if openai_result.get('connection'):
            report_lines.append(f"   –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ: ‚úÖ –£—Å–ø–µ—à–Ω–æ")
        
        # –ü—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å
        profit = self.results.get('profitability', {})
        status = profit.get('status', '‚ö†Ô∏è')
        report_lines.append(f"\nüí∞ –ü—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å: {status}")
        if profit.get('total_trades', 0) > 0:
            report_lines.append(f"   –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {profit['total_trades']}")
            report_lines.append(f"   Win Rate: {profit.get('win_rate', 0):.1f}%")
            report_lines.append(f"   –û–±—â–∏–π PnL: ‚âà${profit.get('estimated_total_pnl_usd', 0):.2f}")
        
        report_lines.append("\n" + "-"*60)
        report_lines.append("="*60)
        
        report = "\n".join(report_lines)
        logger.info(report)
        
        return report
    
    def run_all_checks(self):
        """üöÄ –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫"""
        logger.info("\n" + "="*60)
        logger.info("üöÄ –ó–ê–ü–£–°–ö –ö–û–ú–ü–õ–ï–ö–°–ù–û–ô –ü–†–û–í–ï–†–ö–ò")
        logger.info("="*60)
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
        self.check_disk_space()
        
        # 2. –£–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞
        self.cleanup_junk()
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫
        self.check_libraries()
        
        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ OpenAI API
        self.check_openai_api()
        
        # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏
        self.check_profitability()
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        report = self.generate_report()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_file = self.base_dir / "logs" / "system" / f"health_check_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        report_file.parent.mkdir(parents=True, exist_ok=True)
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
            f.write("\n\n–î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n")
            f.write(json.dumps(self.results, indent=2, ensure_ascii=False, default=str))
        
        logger.info(f"\nüìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
        
        return self.results


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    checker = ServerHealthCheck()
    checker.run_all_checks()


if __name__ == "__main__":
    main()










